# -*- coding: utf-8 -*-
"""CODE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_1mKuCdktKU5s-b4934sEzGLuTdHpP2q

### 0. Install Requirements
"""

!pip install tensorboardX

import os
import sys
import pathlib

"""### 1. Prepare Custom Dataset/Pretrained Weights

#### Master Branch
"""

# Directory and file paths
repo_dir = 'content/Thesis'
dataset_url = 'https://github.com/quin-thifal/Thesis/raw/313cfed38782aa4beab080c762de87b38d92a8a8/dataset.zip'
dataset_zip = 'dataset.zip'
dataset_dir = 'dataset'

# Function to check if we are at the root directory
def at_root(path):
    return path == pathlib.Path('/')

# Navigate up the directory tree if necessary and check for the repo directory
current_path = pathlib.Path.cwd()
while not at_root(current_path):
    if (current_path / repo_dir).exists():
        os.chdir(current_path / repo_dir)
        sys.path.append('.')
        !git pull
        break
    current_path = current_path.parent
else:
    os.chdir(current_path)
    !git clone --branch master --single-branch https://github.com/quin-thifal/Thesis.git {repo_dir}
    os.chdir(repo_dir)
    sys.path.append('.')

# Define the full path to the dataset directory
full_dataset_dir = pathlib.Path(repo_dir) / dataset_dir

# Check if the dataset needs to be downloaded and unzipped
if not full_dataset_dir.exists():
    !wget {dataset_url}
    !unzip -o -d {dataset_dir}/ {dataset_zip}
    os.remove(dataset_zip)

# Prepare project file
!cat project/dm-foot.yml

"""#### Main Branch"""

import os
import pathlib
import sys

# Directory and file paths
repo_dir = 'content/Thesis'
dataset_url = 'https://github.com/quin-thifal/Thesis/raw/313cfed38782aa4beab080c762de87b38d92a8a8/dataset.zip'
dataset_zip = 'dataset.zip'
dataset_dir = 'dataset'

# Function to check if we are at the root directory
def at_root(path):
    return path == pathlib.Path('/')

# Navigate up the directory tree if necessary and check for the repo directory
current_path = pathlib.Path.cwd()
while not at_root(current_path):
    if (current_path / repo_dir).exists():
        os.chdir(current_path / repo_dir)
        sys.path.append('.')
        !git pull
        break
    current_path = current_path.parent
else:
    os.chdir(current_path)
    !git clone --branch main --single-branch https://github.com/quin-thifal/Thesis.git {repo_dir}
    os.chdir(repo_dir)
    sys.path.append('.')

# Define the full path to the dataset directory
full_dataset_dir = pathlib.Path(repo_dir) / dataset_dir

# Check if the dataset needs to be downloaded and unzipped
if not full_dataset_dir.exists():
    !wget {dataset_url}
    !unzip -o -d {dataset_dir}/ {dataset_zip}
    os.remove(dataset_zip)

# Prepare project file
!cat project/dmt2.yml

"""#### Initialize Libraries"""

import cv2
import torch
import random
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from torch.backends import cudnn
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

from backbone import EfficientDetBackbone
from efficientdet.utils import BBoxTransform, ClipBoxes
from utils.utils import preprocess, invert_affine, postprocess

"""### 2. Training

#### Training with weights
"""

!python train.py -c 0 -p dm-foot -n 2 --lr 1e-3 --load_weights weights/h.pth --batch_size 8 --num_epochs 100

"""#### Training without weights"""

!python train.py -c 0 -p dmt2 -n 2 --batch_size 8 --lr 1e-3 --num_epochs 300

"""### 3. Evaluation"""

# Change directory to where the weight files are located
weight_dir = '/content/Thesis/logs/dm-foot'

# Get the most recently modified weight file
files = [f for f in os.listdir(weight_dir) if f.endswith('.pth')]
weight_file = max(files, key=lambda f: os.path.getmtime(os.path.join(weight_dir, f)))

# Print the latest weight file for verification
print(f"Latest weight file: {weight_file}")

# Use the latest weight file in the evaluation script
!python coco_eval.py -c 0 -p dm-foot -w "logs/dm-foot/{weight_file}"

"""### 4. Visualize"""

# Define the root folder paths
train_folder = '/content/Thesis/dataset/dm-foot/train'
val_folder = '/content/Thesis/dataset/dm-foot/val'

# Function to gather data from folder
def gather_data(folder):
    data = {
        'total': 0,
        'sehat': 0,
        'dm': 0,
        'male': 0,
        'female': 0
    }
    for root, dirs, files in os.walk(folder):
        for file in files:
            if file.endswith('.png') or file.endswith('.jpg'):
                data['total'] += 1
                if file.startswith('CG'):
                    data['sehat'] += 1
                elif file.startswith('DM'):
                    data['dm'] += 1
                if '_M_' in file:
                    data['male'] += 1
                elif '_F_' in file:
                    data['female'] += 1
    return data

# Gather data
train_data = gather_data(train_folder)
val_data = gather_data(val_folder)

# Combine data for all
all_data = {
    'total': train_data['total'] + val_data['total'],
    'sehat': train_data['sehat'] + val_data['sehat'],
    'dm': train_data['dm'] + val_data['dm'],
    'male': train_data['male'] + val_data['male'],
    'female': train_data['female'] + val_data['female']
}

# Function to format autopct labels
def make_autopct(values):
    def my_autopct(pct):
        total = sum(values)
        val = int(round(pct*total/100.0))
        return '{p:.1f}%  ({v:d})'.format(p=pct,v=val)
    return my_autopct

# Function to plot pie chart
def plot_pie_chart(ax, labels, sizes, title):
    ax.pie(sizes, labels=labels, autopct=make_autopct(sizes), startangle=140)
    ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
    ax.set_title(title)

# Create a figure with a 3x3 grid of subplots
fig, axs = plt.subplots(3, 3, figsize=(15, 15))

# Plot pie charts
# Graph 1: Total images in train vs val (position 1)
plot_pie_chart(
    axs[0, 0],
    labels=['Train', 'Val'],
    sizes=[train_data['total'], val_data['total']],
    title='Total Images: Train vs Val'
)

# Graph 2: Sehat vs DM (All) (positions 2, 3, 4)
plot_pie_chart(
    axs[1, 0],
    labels=['Sehat', 'DM'],
    sizes=[all_data['sehat'], all_data['dm']],
    title='All: Sehat vs DM'
)
plot_pie_chart(
    axs[1, 1],
    labels=['Sehat', 'DM'],
    sizes=[train_data['sehat'], train_data['dm']],
    title='Train: Sehat vs DM'
)
plot_pie_chart(
    axs[1, 2],
    labels=['Sehat', 'DM'],
    sizes=[val_data['sehat'], val_data['dm']],
    title='Val: Sehat vs DM'
)

# Graph 3: Male vs Female (All) (positions 5, 6, 7)
plot_pie_chart(
    axs[2, 0],
    labels=['Male', 'Female'],
    sizes=[all_data['male'], all_data['female']],
    title='All: Male vs Female'
)
plot_pie_chart(
    axs[2, 1],
    labels=['Male', 'Female'],
    sizes=[train_data['male'], train_data['female']],
    title='Train: Male vs Female'
)
plot_pie_chart(
    axs[2, 2],
    labels=['Male', 'Female'],
    sizes=[val_data['male'], val_data['female']],
    title='Val: Male vs Female'
)

# Hide empty subplots
axs[0, 1].axis('off')
axs[0, 2].axis('off')

plt.tight_layout()
plt.show()

# Configuration
compound_coef = 0
force_input_size = None  # set None to use default size
img_dir = '/content/Thesis/test'
threshold = 0.2
iou_threshold = 0.2
use_cuda = True
use_float16 = False
cudnn.fastest = True
cudnn.benchmark = True

obj_list = ['Diabetes', 'Sehat']

input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]
input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size

# Initialize the model
model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),
                             ratios=[(1.0, 1.0), (1.0, 1.0), (2.0, 0.5)],
                             scales=[1, 1.2599210498948732, 1.5874010519681994])

# Load weights
model.load_state_dict(torch.load('logs/dm-foot/' + weight_file))
model.requires_grad_(False)
model.eval()

if use_cuda:
    model = model.cuda()
if use_float16:
    model = model.half()

# Get all images from the directory
img_names = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]

# Initialize lists for results
results = []

# Create a figure to hold all images and table
fig, axs = plt.subplots(len(img_names), 5, figsize=(36, len(img_names) * 6))  # Adjusted number of columns
plt.subplots_adjust(hspace=0.5)

# Initialize lists for results
data_for_df = []

for idx, img_name in enumerate(img_names):
    img_path = os.path.join(img_dir, img_name)
    ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)

    if use_cuda:
        x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)
    else:
        x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)

    x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)

    with torch.no_grad():
        features, regression, classification, anchors = model(x)

        regressBoxes = BBoxTransform()
        clipBoxes = ClipBoxes()

        out = postprocess(x,
                          anchors, regression, classification,
                          regressBoxes, clipBoxes,
                          threshold, iou_threshold)

    out = invert_affine(framed_metas, out)

    if len(out[0]['rois']) == 0:
        # Add a default prediction box if none are detected
        out[0]['rois'] = np.array([[0, 0, input_size, input_size]])
        out[0]['class_ids'] = np.array([0])
        out[0]['scores'] = np.array([1.0])

    scores = out[0]['scores']
    rois = out[0]['rois']
    class_ids = out[0]['class_ids']

    # Calculate the image center
    img_center = (input_size / 2, input_size / 2)

    # Calculate areas of bounding boxes
    areas = [(x2 - x1) * (y2 - y1) for (x1, y1, x2, y2) in rois]

    if len(scores) > 0:
        # Store predictions
        predictions = list(zip(rois, class_ids, scores, areas))

        # Find the highest probability
        highest_prob_index = np.argmax(scores)
        highest_prob = scores[highest_prob_index]

        # Find the bounding box with the closest delta to the center
        if np.any(scores == highest_prob):
            high_prob_boxes = [pred for pred in predictions if pred[2] == highest_prob]
            centers = [( (x1 + x2) / 2, (y1 + y2) / 2 ) for (x1, y1, x2, y2), _, _, _ in high_prob_boxes]
            distances = [np.sqrt((center[0] - img_center[0])**2 + (center[1] - img_center[1])**2) for center in centers]
            closest_to_center_index = np.argmin(distances)
            best_box_index = [i for i, (box, _, _, _) in enumerate(high_prob_boxes)][closest_to_center_index]
        else:
            best_box_index = random.choice(range(len(predictions)))

        # Find the bounding box with the largest area
        if len(areas) > 0:
            largest_area_index = np.argmax(areas)
        else:
            largest_area_index = random.choice(range(len(predictions)))

        # Find the average probability
        avg_prob = np.mean(scores)
        avg_prob_boxes = [pred for pred in predictions if np.isclose(pred[2], avg_prob)]

        if avg_prob_boxes:
            centers = [( (x1 + x2) / 2, (y1 + y2) / 2 ) for (x1, y1, x2, y2), _, _, _ in avg_prob_boxes]
            distances = [np.sqrt((center[0] - img_center[0])**2 + (center[1] - img_center[1])**2) for center in centers]
            closest_to_center_index = np.argmin(distances)
            best_box_index_avg = [i for i, (box, _, _, _) in enumerate(avg_prob_boxes)][closest_to_center_index]
        else:
            best_box_index_avg = random.choice(range(len(predictions)))

        # Select extra box based on file name
        if img_name.startswith('CG'):
            category = 'Sehat'
        elif img_name.startswith('DM'):
            category = 'Diabetes'
        else:
            category = None

        extra_box_index = None
        if category:
            category_indices = [i for i, class_id in enumerate(class_ids) if obj_list[class_id] == category]
            if category_indices:
                extra_box_index = random.choice(category_indices)
            else:
                extra_box_index = random.choice(range(len(predictions)))

        # Store data for DataFrame only for labels
        data_for_df.append({
            'Image': img_name,
            'Highest Probability Label': obj_list[class_ids[best_box_index]] if len(scores) > 0 else 'N/A',
            'Largest Area Label': obj_list[class_ids[largest_area_index]] if len(areas) > 0 else 'N/A',
            'Average Probability Label': obj_list[class_ids[best_box_index_avg]] if avg_prob_boxes else 'N/A',
            'Extra Box Label': obj_list[class_ids[extra_box_index]] if extra_box_index is not None else 'N/A'
        })

        # Draw boxes on images
        for j in range(len(rois)):
            (x1, y1, x2, y2) = rois[j].astype(int)
            color = (255, 255, 0)  # Keep the color consistent for bounding boxes
            cv2.rectangle(ori_imgs[0], (x1, y1), (x2, y2), color, 2)
            obj = obj_list[class_ids[j]]
            score = float(scores[j])
            cv2.putText(ori_imgs[0], '{}, {:.3f}'.format(obj, score),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        color, 1)

        # Display results
        axs[idx, 0].imshow(cv2.cvtColor(ori_imgs[0], cv2.COLOR_BGR2RGB))
        axs[idx, 0].set_title('Original Image')
        axs[idx, 0].axis('off')

        # Highest Probability Box
        img_with_boxes = ori_imgs[0].copy()
        if len(scores) > 0:
            (x1, y1, x2, y2) = rois[best_box_index].astype(int)
            color = (0, 255, 0)  # Green for highest probability box
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img_with_boxes, '{} {:.3f}'.format(obj_list[class_ids[best_box_index]], scores[best_box_index]),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        axs[idx, 1].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 1].set_title('Highest Prob Box')
        axs[idx, 1].axis('off')

        # Largest Area Box
        img_with_boxes = ori_imgs[0].copy()
        if len(areas) > 0:
            (x1, y1, x2, y2) = rois[largest_area_index].astype(int)
            color = (0, 0, 255)  # Red for largest area box
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img_with_boxes, '{} {:.3f}'.format(obj_list[class_ids[largest_area_index]], scores[largest_area_index]),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        axs[idx, 2].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 2].set_title('Largest Area Box')
        axs[idx, 2].axis('off')

        # Average Probability Box
        img_with_boxes = ori_imgs[0].copy()
        if avg_prob_boxes:
            (x1, y1, x2, y2) = rois[best_box_index_avg].astype(int)
            color = (255, 0, 0)  # Blue for average probability box
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img_with_boxes, '{} {:.3f}'.format(obj_list[class_ids[best_box_index_avg]], avg_prob),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        axs[idx, 3].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 3].set_title('Avg Prob Box')
        axs[idx, 3].axis('off')

        # Extra Box
        img_with_boxes = ori_imgs[0].copy()
        if extra_box_index is not None:
            (x1, y1, x2, y2) = rois[extra_box_index].astype(int)
            color = (255, 255, 255)  # White for extra box
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            cv2.putText(img_with_boxes, '{}'.format(obj_list[class_ids[extra_box_index]]),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
        axs[idx, 4].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 4].set_title('Extra Box')
        axs[idx, 4].axis('off')

# Create DataFrame
df = pd.DataFrame(data_for_df)

plt.show()  # Display the images first

# Display the DataFrame
display(df)

# Configuration
compound_coef = 0
force_input_size = None
img_dir = '/content/Thesis/test'
threshold = 0.2
iou_threshold = 0.2
use_cuda = True
use_float16 = False
cudnn.fastest = True
cudnn.benchmark = True

obj_list = ['Diabetes', 'Sehat']
input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]
input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size

# Initialize the model
model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),
                             ratios=[(1.0, 1.0), (1.0, 1.0), (2.0, 0.5)],
                             scales=[1, 1.2599210498948732, 1.5874010519681994])

# Load weights
model.load_state_dict(torch.load('logs/dm-foot/' + weight_file))
model.requires_grad_(False)
model.eval()

if use_cuda:
    model = model.cuda()
if use_float16:
    model = model.half()

# Get all images from the directory
img_names = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]

# Initialize lists for results
data_for_df = []

# Create a figure to hold all images
fig, axs = plt.subplots(len(img_names), 6, figsize=(36, len(img_names) * 6))  # Adjusted number of columns
plt.subplots_adjust(hspace=0.5)

for idx, img_name in enumerate(img_names):
    img_path = os.path.join(img_dir, img_name)
    ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)

    if use_cuda:
        x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)
    else:
        x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)

    x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)

    with torch.no_grad():
        features, regression, classification, anchors = model(x)

        regressBoxes = BBoxTransform()
        clipBoxes = ClipBoxes()

        out = postprocess(x,
                          anchors, regression, classification,
                          regressBoxes, clipBoxes,
                          threshold, iou_threshold)

    out = invert_affine(framed_metas, out)

    if len(out[0]['rois']) == 0:
        # Add a default prediction box if none are detected
        out[0]['rois'] = np.array([[0, 0, input_size, input_size]])
        out[0]['class_ids'] = np.array([0])
        out[0]['scores'] = np.array([1.0])

    scores = out[0]['scores']
    rois = out[0]['rois']
    class_ids = out[0]['class_ids']

    # Calculate the image center
    img_center = (input_size / 2, input_size / 2)

    # Calculate areas of bounding boxes
    areas = [(x2 - x1) * (y2 - y1) for (x1, y1, x2, y2) in rois]

    if len(scores) > 0:
        # Store predictions
        predictions = list(zip(rois, class_ids, scores, areas))

        # Find the highest probability
        highest_prob_index = np.argmax(scores)
        highest_prob = scores[highest_prob_index]

        # Find the bounding box with the closest delta to the center
        if np.any(scores == highest_prob):
            high_prob_boxes = [pred for pred in predictions if pred[2] == highest_prob]
            centers = [( (x1 + x2) / 2, (y1 + y2) / 2 ) for (x1, y1, x2, y2), _, _, _ in high_prob_boxes]
            distances = [np.sqrt((center[0] - img_center[0])**2 + (center[1] - img_center[1])**2) for center in centers]
            closest_to_center_index = np.argmin(distances)
            best_box_index = [i for i, (box, _, _, _) in enumerate(high_prob_boxes)][closest_to_center_index]
        else:
            best_box_index = random.choice(range(len(predictions)))

        # Find the bounding box with the largest area
        if len(areas) > 0:
            largest_area_index = np.argmax(areas)
        else:
            largest_area_index = random.choice(range(len(predictions)))

        # Find the average probability
        avg_prob = np.mean(scores)
        avg_prob_boxes = [pred for pred in predictions if np.isclose(pred[2], avg_prob)]

        if avg_prob_boxes:
            centers = [( (x1 + x2) / 2, (y1 + y2) / 2 ) for (x1, y1, x2, y2), _, _, _ in avg_prob_boxes]
            distances = [np.sqrt((center[0] - img_center[0])**2 + (center[1] - img_center[1])**2) for center in centers]
            closest_to_center_index = np.argmin(distances)
            best_box_index_avg = [i for i, (box, _, _, _) in enumerate(avg_prob_boxes)][closest_to_center_index]
        else:
            best_box_index_avg = random.choice(range(len(predictions)))

        # Select extra box based on file name
        if img_name.startswith('CG'):
            category = 'Sehat'
        elif img_name.startswith('DM'):
            category = 'Diabetes'
        else:
            category = None

        extra_box_index = None
        if category:
            category_indices = [i for i, class_id in enumerate(class_ids) if obj_list[class_id] == category]
            if category_indices:
                extra_box_index = random.choice(category_indices)
            else:
                extra_box_index = random.choice(range(len(predictions)))

        # Store data for DataFrame only for labels
        data_for_df.append({
            'Image': img_name,
            'Highest Probability Label': obj_list[class_ids[best_box_index]] if len(scores) > 0 else 'N/A',
            'Largest Area Label': obj_list[class_ids[largest_area_index]] if len(areas) > 0 else 'N/A',
            'Average Probability Label': obj_list[class_ids[best_box_index_avg]] if avg_prob_boxes else 'N/A',
            'Extra Box Label': obj_list[class_ids[extra_box_index]] if extra_box_index is not None else 'N/A'
        })

        # Draw all boxes on the original image
        img_with_all_boxes = ori_imgs[0].copy()
        for j in range(len(rois)):
            (x1, y1, x2, y2) = rois[j].astype(int)
            if obj_list[class_ids[j]] == 'Diabetes':
                color = (0, 0, 255)  # Red for Diabetes
            elif obj_list[class_ids[j]] == 'Sehat':
                color = (0, 255, 0)  # Green for Sehat
            else:
                color = (255, 255, 255)  # Default to white

            cv2.rectangle(img_with_all_boxes, (x1, y1), (x2, y2), color, 2)
            obj = obj_list[class_ids[j]]
            score = float(scores[j])
            cv2.putText(img_with_all_boxes, '{}, {:.3f}'.format(obj, score),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        color, 1)

        # Display results
        axs[idx, 0].imshow(cv2.cvtColor(ori_imgs[0], cv2.COLOR_BGR2RGB))
        axs[idx, 0].set_title(f'Original Image {img_name}')
        axs[idx, 0].axis('off')

        axs[idx, 1].imshow(cv2.cvtColor(img_with_all_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 1].set_title('All Predictions')
        axs[idx, 1].axis('off')

        # Highest Probability Box
        img_with_boxes = ori_imgs[0].copy()
        if len(scores) > 0:
            (x1, y1, x2, y2) = rois[best_box_index].astype(int)
            color = (0, 255, 255)  # Cyan
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            obj = obj_list[class_ids[best_box_index]]
            score = float(scores[best_box_index])
            cv2.putText(img_with_boxes, '{}, {:.3f}'.format(obj, score),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        color, 1)

        axs[idx, 2].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 2].set_title('Highest Probability Box')
        axs[idx, 2].axis('off')

        # Largest Area Box
        img_with_boxes = ori_imgs[0].copy()
        if len(areas) > 0:
            (x1, y1, x2, y2) = rois[largest_area_index].astype(int)
            color = (255, 0, 0)  # Blue
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            obj = obj_list[class_ids[largest_area_index]]
            score = float(scores[largest_area_index])
            cv2.putText(img_with_boxes, '{}, {:.3f}'.format(obj, score),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        color, 1)

        axs[idx, 3].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 3].set_title('Largest Area Box')
        axs[idx, 3].axis('off')

        # Average Probability Box
        img_with_boxes = ori_imgs[0].copy()
        if avg_prob_boxes:
            (x1, y1, x2, y2) = rois[best_box_index_avg].astype(int)
            color = (255, 255, 0)  # Yellow
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            obj = obj_list[class_ids[best_box_index_avg]]
            score = float(scores[best_box_index_avg])
            cv2.putText(img_with_boxes, '{}, {:.3f}'.format(obj, score),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        color, 1)

        axs[idx, 4].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 4].set_title('Average Probability Box')
        axs[idx, 4].axis('off')

        # Random Box
        img_with_boxes = ori_imgs[0].copy()
        if len(predictions) > 0:
            (x1, y1, x2, y2) = rois[extra_box_index].astype(int)
            color = (0, 128, 128)  # Teal
            cv2.rectangle(img_with_boxes, (x1, y1), (x2, y2), color, 2)
            obj = obj_list[class_ids[extra_box_index]]
            score = float(scores[extra_box_index])
            cv2.putText(img_with_boxes, '{}, {:.3f}'.format(obj, score),
                        (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                        color, 1)

        axs[idx, 5].imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))
        axs[idx, 5].set_title('Random Box')
        axs[idx, 5].axis('off')

plt.show()

# Create DataFrame from results
df = pd.DataFrame(data_for_df)
display(df)

"""### 5. Matrix Display"""

# Determine real labels
df['Real Label'] = df['Image'].apply(lambda x: 'Sehat' if x.startswith('CG') else 'Diabetes')

# Extract labels for each method
labels = ['Highest Probability Label', 'Largest Area Label', 'Average Probability Label', 'Extra Box Label']

# Initialize a dictionary to hold confusion matrices
cm_dict = {}

# Create confusion matrices for each method
for label in labels:
    cm = confusion_matrix(df['Real Label'], df[label], labels=['Sehat', 'Diabetes'])
    cm_dict[label] = cm

# Plot confusion matrices
fig, axs = plt.subplots(1, len(labels), figsize=(20, 5))

for ax, (label, cm) in zip(axs, cm_dict.items()):
    cmd = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Sehat', 'Diabetes'])
    cmd.plot(ax=ax, cmap=plt.cm.Blues, values_format='d')
    ax.set_title(f'Confusion Matrix - {label}')

plt.tight_layout()
plt.show()